name: Ollama DeepSeek report
'on': workflow_dispatch

jobs:
  analyze:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4

    # 1. Cache modelli
    - name: Restore Ollama cache
      uses: actions/cache@v4
      with:
        path: ~/.ollama
        key: ollama-${{ runner.os }}-deepseek-r1

    # 2. Install & serve
    - name: Install Ollama
      run: curl -fsSL https://ollama.com/install.sh | sh
    - name: Start Ollama
      run: ollama serve &

    # 3. Ensure model present (fast if cached)
    - name: Pull model
      run: ollama pull deepseek-r1:latest

    # 4. Generate report in parallel
    - name: DeepSeek analysis
      run: |
        rm -f deepseek_report.md
        parallel -j $(nproc) --bar '
          file={};
          {
            echo "## Analysis of $file";
            curl -s -d "{\"model\":\"deepseek-r1:latest\",\"stream\":false,\
            \"options\":{\"num_predict\":256},\
            \"prompt\":\"Please analyze the code in $file and suggest improvements and document its functionality.\"}" \
            http://localhost:11434/api/generate
            echo
          } >> deepseek_report.md
        ' :::: file_list.txt